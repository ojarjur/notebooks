{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with the Stackdriver Monitoring API\n",
    "\n",
    "Cloud Datalab provides an environment for working with your data. This includes data that is being managed within the [Stackdriver Monitoring API](https://cloud.google.com/monitoring/api/v3/). This notebook introduces some of the APIs that Cloud Datalab provides for working with the monitoring data, and allows you to try them out on your own project.\n",
    "\n",
    "The main focus of this API is to allow you to query time series data for your monitored resources. The time series, and it's metadata are returned as [pandas DataFrame](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) objects. `pandas` is a widely used library for data manipulation, and is well suited to working with time series data.\n",
    "\n",
    "**Note**: This notebook will show you how to use this API with your own project. The charts included here are from a sample project that you will not have access to. For all cells to run without errors, the following must hold:\n",
    "* The default project must be set\n",
    "* This project must have at least one GCE Instance. You can create an instance at the following link: https://console.cloud.google.com/compute/instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the API and setting up the default project\n",
    "\n",
    "The Monitoring functionality is contained within the `datalab.stackdriver.monitoring` module.\n",
    "\n",
    "If the default project is not already set via the environment variable `$PROJECT_ID`, you must do so using `'set_datalab_project_id'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from google.datalab.stackdriver import monitoring as gcm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List names of Compute Engine CPU metrics\n",
    "\n",
    "Here we use IPython [cell magics](http://ipython.readthedocs.io/en/stable/interactive/magics.html) to list the CPU metrics. The `Labels` column shows that `instance_name` is a metric label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Metric type</th><th>Display name</th><th>Kind</th><th>Value</th><th>Unit</th><th>Labels</th></tr><tr><td>compute.googleapis.com/instance/cpu/reserved_cores</td><td>Reserved cores</td><td>GAUGE</td><td>DOUBLE</td><td>1</td><td>instance_name</td></tr><tr><td>compute.googleapis.com/instance/cpu/usage_time</td><td>CPU usage</td><td>DELTA</td><td>DOUBLE</td><td>s</td><td>instance_name</td></tr><tr><td>compute.googleapis.com/instance/cpu/utilization</td><td>CPU utilization</td><td>GAUGE</td><td>DOUBLE</td><td>1</td><td>instance_name</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sd monitoring metrics list --type compute*/cpu/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List monitored resource types related to GCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Resource type</th><th>Display name</th><th>Labels</th></tr><tr><td>gce_disk</td><td>GCE Disk</td><td>project_id, disk_id, zone</td></tr><tr><td>gce_instance</td><td>GCE VM Instance</td><td>project_id, instance_id, zone</td></tr><tr><td>gce_router</td><td>Cloud Router</td><td>project_id, router_id, region</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sd monitoring resource_types list --type gce*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying time series data\n",
    "\n",
    "The `Query` class allows users to query and access the monitoring time series data.\n",
    "\n",
    "Many useful methods of the `Query` class are actually defined by the base class, which is provided by the `google-cloud-python` library. These methods include:\n",
    "* `select_metrics`:  filters the query based on metric labels.\n",
    "* `select_resources`: filters the query based on resource type and labels.\n",
    "* `align`: aligns the query along the specified time intervals.\n",
    "* `reduce`: applies aggregation to the query.\n",
    "* `as_dataframe`: returns the time series data as a `pandas` DataFrame object.\n",
    "\n",
    "Reference documentation for the `Query` base class is available [here](http://gcloud-python.readthedocs.org/en/latest/monitoring-query.html). You can also get help from inside the notebook by calling the `help` function on any class, object or method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method select_interval in module google.cloud.monitoring.query:\n",
      "\n",
      "select_interval(self, end_time, start_time=None) unbound google.datalab.stackdriver.monitoring._query.Query method\n",
      "    Copy the query and set the query time interval.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        import datetime\n",
      "    \n",
      "        now = datetime.datetime.utcnow()\n",
      "        query = query.select_interval(\n",
      "            end_time=now,\n",
      "            start_time=now - datetime.timedelta(minutes=5))\n",
      "    \n",
      "    As a convenience, you can alternatively specify the end time and\n",
      "    an interval duration when you create the query initially.\n",
      "    \n",
      "    :type end_time: :class:`datetime.datetime`\n",
      "    :param end_time: The end time (inclusive) of the time interval\n",
      "        for which results should be returned, as a datetime object.\n",
      "    \n",
      "    :type start_time: :class:`datetime.datetime` or None\n",
      "    :param start_time: The start time (exclusive) of the time interval\n",
      "        for which results should be returned, as a datetime object.\n",
      "        If not specified, the interval is a point in time.\n",
      "    \n",
      "    :rtype: :class:`Query`\n",
      "    :returns: The new query object.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(gcm.Query.select_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the query\n",
    "\n",
    "During intialization, the metric type and the time interval need to be specified. For interactive use, the metric type has a default value. The simplest way to specify the time interval that ends `now` is to use the arguments `days`, `hours`, and `minutes`.\n",
    "\n",
    "In the cell below, we initialize the query to load the time series for `CPU Utilization` for the last two hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query_cpu = gcm.Query('compute.googleapis.com/instance/cpu/utilization', hours=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the metadata\n",
    "\n",
    "The method `metadata()` returns a `QueryMetadata` object. It contains the following information about the time series matching the query:\n",
    "* resource types\n",
    "* resource labels and their values\n",
    "* metric labels and their values\n",
    "\n",
    "This helps you understand the structure of the time series data, and makes it easier to modify the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metadata_cpu = query_cpu.metadata().as_dataframe()\n",
    "metadata_cpu.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the instance names from the metadata\n",
    "Next, we read in the instance names from the metadata, and use it in filtering the time series data below. If there are no GCE instances in this project, the cells below will raise errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if metadata_cpu.empty:\n",
    "  sys.stderr.write('This project has no GCE instances. The remaining notebook '\n",
    "                   'will raise errors!')\n",
    "else:\n",
    "  instance_names = sorted(list(metadata_cpu['metric.labels']['instance_name']))\n",
    "  print 'First 5 instance names: %s' % ([str(name) for name in instance_names[:5]],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering by metric label\n",
    "\n",
    "We first filter `query_cpu` defined earlier to include only the first instance. Next, calling `as_dataframe` gets the results from the monitoring API, and converts them into a `pandas` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query_cpu_single_instance = query_cpu.select_metrics(instance_name=instance_names[0])\n",
    "\n",
    "# Get the query results as a pandas DataFrame and look at the last 5 rows.\n",
    "data_single_instance = query_cpu_single_instance.as_dataframe(label='instance_name')\n",
    "data_single_instance.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying the time series as a linechart\n",
    "\n",
    "We can plot the time series data by calling the plot method of the dataframe. The `pandas` library uses `matplotlib` for plotting, so you can learn more about it [here](http://matplotlib.org/users/pyplot_tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# N.B. A useful trick is to assign the return value of plot to _ \n",
    "# so that you don't get text printed before the plot itself.\n",
    "\n",
    "_ = data_single_instance.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating the query\n",
    "\n",
    "You can aggregate or summarize time series data along various dimensions.\n",
    "* In the first stage, data in a time series is [aligned](https://cloud.google.com/monitoring/api/ref_v3/rest/v3/projects.timeSeries/list#Aligner) to a specified period.\n",
    "* In the second stage, data from multiple time series is combined, or [reduced](https://cloud.google.com/monitoring/api/ref_v3/rest/v3/projects.timeSeries/list#Reducer), into one time series. \n",
    "\n",
    "Not all alignment and reduction options are applicable to all time series, depending on their metric type and value type. Alignment and reduction may change the metric type or value type of a time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aligning the query\n",
    "\n",
    "For multiple time series, aligning the data is recommended. Aligned data is more compact to read from the Monitoring API, and lends itself better to visualizations.\n",
    "\n",
    "The alignment period can be specified using the arguments `hours`, `minutes`, and `seconds`. In the cell below, we do the following:\n",
    "* select a subset of the instances by using a prefix of the first instance name\n",
    "* align the time series to 5 minute intervals using an `'ALIGN_MEAN'` method.\n",
    "* plot the time series, and adjust the legend to be outside the plot. You can learn more about legend placement [here]( http://matplotlib.org/users/legend_guide.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter the query by a common instance name prefix.\n",
    "common_prefix = instance_names[0].split('-')[0]\n",
    "query_cpu_aligned = query_cpu.select_metrics(instance_name_prefix=common_prefix)\n",
    "\n",
    "# Align the query to have data every 5 minutes.\n",
    "query_cpu_aligned = query_cpu_aligned.align(gcm.Aligner.ALIGN_MEAN, minutes=5)\n",
    "data_multiple_instances = query_cpu_aligned.as_dataframe(label='instance_name')\n",
    "\n",
    "# Display the data as a linechart, and move the legend to the right of it.\n",
    "_ = data_multiple_instances.plot().legend(loc=\"upper left\", bbox_to_anchor=(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing the query\n",
    "\n",
    "In order to combine the data across multiple time series, the `reduce()` method can be used. The fields to be retained after aggregation must be specified in the method.\n",
    "\n",
    "For example, to aggregate the results by the zone, `'resource.zone'` can be specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query_cpu_reduced = query_cpu_aligned.reduce(gcm.Reducer.REDUCE_MEAN, 'resource.zone')\n",
    "data_per_zone = query_cpu_reduced.as_dataframe('zone')\n",
    "data_per_zone.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying the time series as a heatmap\n",
    "\n",
    "Let us look at the time series at the instance level as a heatmap. A heatmap is a compact representation of the data, and can often highlight patterns.\n",
    "\n",
    "The diagram below shows the instances along rows, and the timestamps along columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import seaborn\n",
    "\n",
    "# Set the size of the heatmap to have a better aspect ratio.\n",
    "div_ratio = 1 if len(data_multiple_instances.columns) == 1 else 2.0\n",
    "width, height = (size/div_ratio for size in data_multiple_instances.shape)\n",
    "matplotlib.pyplot.figure(figsize=(width, height))\n",
    "\n",
    "# Display the data as a heatmap. The timestamps are converted to strings\n",
    "# for better readbility.\n",
    "_ = seaborn.heatmap(data_multiple_instances.T,\n",
    "                    xticklabels=data_multiple_instances.index.map(str),\n",
    "                    cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-level headers\n",
    "\n",
    "If you don't provide any labels to `as_dataframe`, it returns all the resource and metric labels present in the time series as a multi-level header.\n",
    "\n",
    "This allows you to filter, and aggregate the data more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_multi_level = query_cpu_aligned.as_dataframe()\n",
    "data_multi_level.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the dataframe\n",
    "\n",
    "Let us filter the multi-level dataframe based on the common prefix. Applying the filter will look across all column headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Finding pattern \"%s\" in the dataframe headers' % (common_prefix,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_multi_level.filter(regex=common_prefix).tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate columns in the dataframe\n",
    "\n",
    "Here, we aggregate the multi-level dataframe at the `zone` level. This is similar to applying reduction using `'REDUCE_MEAN'` on the field `'resource.zone'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_multi_level.groupby(level='zone', axis=1).mean().tail(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
